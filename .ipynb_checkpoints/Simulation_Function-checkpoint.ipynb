{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform necessary imports and define global variables\n",
    "- Note that simulation csv files will be overwritten if using same simulation variables as a previous attempt...\n",
    "  - Vars in filename == (number_of_simulations, noise_ratio, number_of_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import poisson\n",
    "from IPython.display import clear_output\n",
    "import scipy as sc\n",
    "import os, re, random, math, time\n",
    "\n",
    "# Define important global variables\n",
    "batches = 5\n",
    "number_of_simulations = 20  #more than 20 simulations at a time tends to produce memory issues, refer to batches to add more sims\n",
    "noise_ratios = [0.05, 0.5, 0.75, 0.8, 0.9, 0.95]\n",
    "sample_of_orders = 100\n",
    "number_of_orders = 10000  #total number of order quantities to generate prior to sampling\n",
    "ratio_poisson_per = 0.95\n",
    "ratio_poisson_com = 1 - ratio_poisson_per\n",
    "lam_poisson_per = 1   #lambda for personal poisson distribution (value that distribution is centered around)\n",
    "lam_poisson_com = 50  #lambda for commercial poisson distribution (value that distribution is centered around)\n",
    "num_poisson_per = int(number_of_orders * ratio_poisson_per)  #number of small order quantities to generate prior to sampling\n",
    "num_poisson_com = int(number_of_orders * ratio_poisson_com)  #number of large order quantities to generate prior to sampling\n",
    "\n",
    "# Read in our file containing product info - Finished Goods and corresponding Parts\n",
    "df_parts = pd.read_csv('finished_good_parts.csv')\n",
    "\n",
    "# Define path to OUTPUT folder where our serviceability csv files will be located\n",
    "PATH_TO_OUTPUT = os.path.join(os.getcwd(), 'Sericeability_Output')\n",
    "# Make directory if specified path doesn't exist\n",
    "if not os.path.exists(PATH_TO_OUTPUT):\n",
    "    os.mkdir(PATH_TO_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulations(simulations, noise_list, batches):\n",
    "    for batch in range(batches):\n",
    "        # Run simulations for each of our passed in noise_ratios\n",
    "        for noise in noise_list:\n",
    "            # Initialize fg_serviceability and pt_serviceability DataFrames\n",
    "            fg_serviceability = pd.DataFrame()\n",
    "            pt_serviceability = pd.DataFrame()\n",
    "            full_serviceability = pd.DataFrame()\n",
    "\n",
    "            print(\"=== Beginning Simulations - NoiseRatio {} - Batch {} ===\".format(noise, (batch+1)))\n",
    "            for sim_number in range(simulations):\n",
    "                start_time = time.time()\n",
    "\n",
    "                # Generate list of integers 1-sample_of_orders to use as identifying ORDER NUMBER's\n",
    "                order_number = np.arange(1,(sample_of_orders+1))\n",
    "                # Generate random list of integers (1-5) as the FINISHED GOOD purchased in each order\n",
    "                FG = [random.randrange(1, 6, 1) for _ in range(sample_of_orders)]\n",
    "\n",
    "                '''\n",
    "                Generate order QUANTITIES (number of Finished Good ordered).\n",
    "                Due to strange poisson distribution we are trying to emulate we build 2 distributions:\n",
    "                s - list of smaller order quantities to represent personal orders, w/ poisson dist centered around 3\n",
    "                s_larger - list of larger order quantities to represent company orders, w/ poisson dist centered around 50\n",
    "                '''\n",
    "                s = 1 + np.random.poisson(lam_poisson_per, num_poisson_per) \n",
    "                s_larger = np.random.poisson(lam_poisson_com, num_poisson_com)\n",
    "\n",
    "                # Combine our 2 sets and remove all quantities equal to 0\n",
    "                s_combined = [*s,*s_larger]\n",
    "                s_combined[:]=(value for value in s_combined if value != 0)\n",
    "\n",
    "                # Take a random sample of size (sample_of_orders) from our poisson distribution of order QUANTITIES\n",
    "                order_quantities = np.random.choice(s_combined, sample_of_orders, replace=False)\n",
    "                # Clear memory\n",
    "                del s_combined\n",
    "\n",
    "                # Turn our 3 lists created above into a DataFrame\n",
    "                df_orders = pd.DataFrame({'Order Number':order_number, 'Finished Good':FG, 'Order Qty':order_quantities})\n",
    "\n",
    "                # Combine all of our ORDER and PART information into a full DataFrame of Simulated Order Information\n",
    "                df_full = df_orders.merge(df_parts, on=\"Finished Good\", how=\"outer\")\n",
    "\n",
    "                # Create new column 'qty_on_order' to show total number of parts required (some FG require 2 of the same part to build)\n",
    "                df_full['qty_on_order'] = df_full['Order Qty']*df_full['Quantity']\n",
    "                # Create null column 'fulfilled_parts' that will be updated later\n",
    "                df_full['fulfilled_parts'] = np.nan\n",
    "\n",
    "                # Make new DataFrame to represent INVENTORY on hand\n",
    "                df_inventory = df_full.groupby('Item_Number')[['qty_on_order']].sum()\n",
    "                df_inventory.reset_index(level=0, inplace=True)\n",
    "                # SUM up the qty_on_order grouped by each Item_Number and multiply by noise for 'Inventory' levels\n",
    "                df_inventory['Inventory'] = df_inventory['qty_on_order'].apply(lambda x: math.ceil (x*noise))\n",
    "\n",
    "                '''\n",
    "                Loop through our orders sequentially and attempt to fulfill orders part-by-part.\n",
    "                Compare the qty_on_order of each part to our inventory levels of that part (or Item_Number).\n",
    "                If there are enough parts in inventory set 'fulfilled_parts' to True, and subtract required\n",
    "                qty_on_order from our current inventory.\n",
    "                Otherwise set our 'fulfilled_parts' to False, and do NOT attempt to deplete inventory levels.\n",
    "                '''\n",
    "                for i in range(1,(sample_of_orders+1)):\n",
    "                    # Find all parts and required quantities for Order Number i (1 through 100) \n",
    "                    current_order = df_full[df_full['Order Number'] == i]\n",
    "                    # Iterate through each part on the current_order\n",
    "                    for j in range(len(current_order)):\n",
    "                        part = current_order.iloc[j]['Item_Number']\n",
    "                        qty = current_order.iloc[j]['qty_on_order']\n",
    "                        on_hand = df_inventory['Inventory'][df_inventory['Item_Number']==part].values[0]\n",
    "                        # Check to see if we have enough parts on hand\n",
    "                        if ((on_hand - qty) > 0):\n",
    "                            # if so set new column ('Fulfilled') to True\n",
    "                            df_full.loc[(df_full['Order Number']==i) & (df_full['Item_Number']==part),'fulfilled_parts'] = True\n",
    "                            # subtract qty (quantity of current part for the current order) from inventory on hand\n",
    "                            df_inventory.loc[df_inventory['Item_Number']==part, 'Inventory'] = df_inventory['Inventory'][df_inventory['Item_Number']==part] - qty\n",
    "                            #print(df_parts['Inventory'][df_parts['Item_Number']==part])\n",
    "\n",
    "                        # If we don't have enough parts set 'Fulfilled' value to False\n",
    "                        else:\n",
    "                            df_full.loc[(df_full['Order Number']==i) & (df_full['Item_Number']==part),'fulfilled_parts'] = False\n",
    "                # Clear memory\n",
    "                del df_inventory\n",
    "\n",
    "                # Add new columns for each trial onto our existing fg_ and pt_serviceability\n",
    "                fg_col_name = \"FGS_\"+str(sim_number+1).zfill(3)\n",
    "                pt_col_name = \"PTS_\" + str(sim_number+1).zfill(3)\n",
    "\n",
    "                # Group by Order Number and Finished Good and get average of fulfilled_parts column\n",
    "                fg_fulfillment = df_full.groupby(['Order Number', 'Finished Good'])[['fulfilled_parts']].mean()\n",
    "                fg_fulfillment.reset_index(level=1, inplace=True)\n",
    "                fg_fulfillment.reset_index(level=0, inplace=True)\n",
    "\n",
    "                # Set all 'fulfilled_parts' values less than 1 equal to 0 (i.e. order cannot be fully fulfilled/machine not built)\n",
    "                fg_fulfillment.loc[(fg_fulfillment['fulfilled_parts'] < 1), 'fulfilled_parts'] = 0\n",
    "\n",
    "                # For first simulation create our fg_ and pt_serviceability DataFrames\n",
    "                if sim_number == 0:\n",
    "                    # FINISHED GOODS level\n",
    "                    fg_serviceability = fg_fulfillment.groupby('Finished Good')[['fulfilled_parts']].mean()\n",
    "                    fg_serviceability.reset_index(level=0, inplace=True)\n",
    "                    fg_serviceability = fg_serviceability.rename(columns={\"fulfilled_parts\":fg_col_name})\n",
    "                    del fg_fulfillment\n",
    "                    # PARTS level\n",
    "                    pt_serviceability = df_full.groupby(['Item_Number'])[['fulfilled_parts']].mean()\n",
    "                    pt_serviceability.reset_index(level=0, inplace=True)\n",
    "                    pt_serviceability = pt_serviceability.rename(columns={\"fulfilled_parts\":pt_col_name})\n",
    "                    # FULL - break down by both FG and PT \n",
    "                    full_serviceability = df_full.groupby(['Finished Good','Item_Number'])[['fulfilled_parts']].mean()\n",
    "                    full_serviceability.reset_index(level=0, inplace=True)\n",
    "                    full_serviceability = full_serviceability.rename(columns={\"fulfilled_parts\":pt_col_name})\n",
    "                # Otherwise create new information and merge onto existing fg_ and pt_serviceability DataFrames\n",
    "                else:\n",
    "                    # FINISHED GOODS level\n",
    "                    fg_new = fg_fulfillment.groupby('Finished Good')[['fulfilled_parts']].mean()\n",
    "                    fg_new.reset_index(level=0, inplace=True)\n",
    "                    fg_serviceability = fg_serviceability.merge(fg_new, left_on='Finished Good', right_on='Finished Good', how='outer')\n",
    "                    fg_serviceability = fg_serviceability.rename(columns={\"fulfilled_parts\":fg_col_name})\n",
    "                    # Clear Memory\n",
    "                    del fg_new, fg_fulfillment\n",
    "                    # PARTS level\n",
    "                    pt_new = df_full.groupby(['Item_Number'])[['fulfilled_parts']].mean()\n",
    "                    pt_new.reset_index(level=0, inplace=True)\n",
    "                    pt_serviceability = pt_serviceability.merge(pt_new, left_on='Item_Number', right_on='Item_Number', how='outer')\n",
    "                    pt_serviceability = pt_serviceability.rename(columns={\"fulfilled_parts\":pt_col_name})\n",
    "                    # Clear Memory\n",
    "                    del pt_new\n",
    "                    # FULL - break down by both FG and PT\n",
    "                    full_new = df_full.groupby(['Finished Good','Item_Number'])[['fulfilled_parts']].mean()\n",
    "                    full_new.reset_index(level=0, inplace=True)\n",
    "                    full_serviceability = full_serviceability.merge(full_new, on=['Finished Good','Item_Number'], how='outer')\n",
    "                    full_serviceability = full_serviceability.rename(columns={\"fulfilled_parts\":pt_col_name})\n",
    "                    del full_new\n",
    "\n",
    "                print(\"--- {}s seconds for simulation {} ---\".format((time.time() - start_time), (sim_number+1)))\n",
    "\n",
    "            # Create fg_, pt_, and full_serviceability filename's from relevant simulation information\n",
    "            fg_filename = \"FGS_\"+str(simulations)+\"Simulations_\"+str(int(noise*100))+\"Noise_\"+str(sample_of_orders)+\"Orders_Batch\"+str(batch+1)+\".csv\"\n",
    "            pt_filename = \"PTS_\"+str(simulations)+\"Simulations_\"+str(int(noise*100))+\"Noise_\"+str(sample_of_orders)+\"Orders_Batch\"+str(batch+1)+\".csv\"\n",
    "            full_filename = \"FULL_\"+str(simulations)+\"Simulations_\"+str(int(noise*100))+\"Noise_\"+str(sample_of_orders)+\"Orders_Batch\"+str(batch+1)+\".csv\"\n",
    "            # Join fg_ and pt_filename's with PATH_TO_OUTPUT, specified in first cell above\n",
    "            PATH_FG_OUT = os.path.join(PATH_TO_OUTPUT, fg_filename)\n",
    "            PATH_PT_OUT = os.path.join(PATH_TO_OUTPUT, pt_filename)\n",
    "            PATH_FL_OUT = os.path.join(PATH_TO_OUTPUT, full_filename)\n",
    "            # Output our simulated serviceability data as csv files\n",
    "            fg_serviceability.to_csv(PATH_FG_OUT)\n",
    "            pt_serviceability.to_csv(PATH_PT_OUT)\n",
    "            full_serviceability.to_csv(PATH_FL_OUT)\n",
    "            # Clear memory and output\n",
    "            del fg_serviceability, pt_serviceability, full_serviceability\n",
    "            clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run function  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Simulations Finished ===\n"
     ]
    }
   ],
   "source": [
    "run_simulations(number_of_simulations, noise_ratios, batches)\n",
    "print('=== Simulations Finished ===')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
